{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13b2162c-86a6-4830-a706-32a2b3052564",
   "metadata": {},
   "source": [
    "# **This notebook aims to extract data from a correctly formatted CSV file and adapt it to the pangeo-fish format**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b00244c-fe99-4c46-b651-aab892497506",
   "metadata": {},
   "source": [
    "### **Necessary imports**\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0e3fa4-a1ec-4df6-93e8-d0318869c065",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from data_conversion import extract_tagging_events\n",
    "from data_conversion import create_metadata_file\n",
    "from data_conversion import extract_name\n",
    "from data_conversion import format_date\n",
    "from data_conversion import extract_DST\n",
    "from data_conversion import convert_to_utc_with_formatting\n",
    "\n",
    "import csv\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348073dc-2c82-4c7f-9e33-ddb3eb3f31c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "remote = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ec15c7-0045-4124-b40e-4e294ed7b96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Test with the tag NO_A12667\n",
    "### These two paths will be used as an example to see if the full data extraction works correctly\n",
    "tag_id = \"DK_A10627\"\n",
    "csv_path = f\"s3://gfts-ifremer/tags/bargip/raw/{tag_id}.CSV\"  # Path to the raw csv file, where the code will extract data from. Update with yours to adapt\n",
    "destination = f\"s3://gfts-ifremer/tags/bargip/clean_demo/{tag_id}/\"  # Folder where you want to write your the different files. Update with yours to adapt\n",
    "\n",
    "if not remote:\n",
    "    os.makedirs(destination, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9febac8-6c0e-433f-a637-4eb1dd3569ac",
   "metadata": {},
   "source": [
    "___\n",
    "### 1. **Extracting the tagging events**\n",
    "In this section, we try to test and compare how to extract the necessary information for the tagging events (i.e., time and position for release, fish death, (recapture?))\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5549ae-3722-40a3-8dc6-4b86c7958d02",
   "metadata": {},
   "source": [
    "See below the steps that the extract_DST function does: \n",
    "\n",
    "- **Purpose**:\n",
    "  - Extracts releasing date, presumed fish death date, and fish release/recapture positions from a CSV file.\n",
    "\n",
    "- **Initialization**:\n",
    "  - Initializes variables for storing dates (`release_date`, `fish_death`) and coordinates (`lon`, `lat`).\n",
    "\n",
    "- **Processing CSV**:\n",
    "  - Opens the CSV file and iterates through each line.\n",
    "\n",
    "- **Data Extraction**:\n",
    "  - Extracts releasing date and presumed fish death date.\n",
    "  - Formats latitude and longitude coordinates for fish release/recapture positions.\n",
    "\n",
    "- **DataFrame Creation**:\n",
    "  - Constructs a DataFrame with event names, dates, longitude, and latitude.\n",
    "  - Returns the DataFrame containing tagging events data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1185b8-504e-442a-81f2-d2660e7f7e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import s3fs\n",
    "\n",
    "s3 = s3fs.S3FileSystem(\n",
    "    anon=False,\n",
    "    client_kwargs={\n",
    "        \"endpoint_url\": \"https://s3.gra.perf.cloud.ovh.net\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d497b3ca-87cb-4269-9ea2-a57d775404a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### See the function tagging_events in the file data_conversion.py for further information\n",
    "tagging_events = extract_tagging_events(\n",
    "    csv_path, time_zone=\"Europe/Paris\", remote=remote\n",
    ")\n",
    "te_save_path = destination + \"tagging_events.csv\"\n",
    "# tagging_events.to_csv(te_save_path,index=False)\n",
    "tagging_events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd639af-9ae5-4acf-a6cc-80c98c864f7a",
   "metadata": {},
   "source": [
    "___\n",
    "### 2. **Creating the metadata JSON file**\n",
    "In this section, we try to test and compare how to extract the necessary information for the metatdat.json file.  \n",
    "___\n",
    "- **Purpose**:\n",
    "  - Creates a metadata JSON file based on provided data path and destination path.\n",
    "\n",
    "- **Initialization**:\n",
    "  - Retrieves tag name from the provided file path using a helper function.\n",
    "  - Initializes metadata with tag ID, scientific name, common name, and project information.\n",
    "\n",
    "- **Metadata Construction**:\n",
    "  - Constructs a dictionary (`metadata`) containing tag ID, scientific name (\"Dicentrarchus labrax\"), common name (\"European seabass\"), and project name (\"BARGIP\").\n",
    "\n",
    "- **File Writing**:\n",
    "  - Specifies the filename as \"metadata.json\" and constructs the full destination path.\n",
    "  - Writes the metadata dictionary to a JSON file at the destination path.\n",
    "\n",
    "- **Result**:\n",
    "  - No return value; a metadata JSON file is created at the specified destination path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a9ba62-2d65-4d3d-bc26-9d52a0cc85ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "### See data_conversion.py for more information about create_metadata_file function\n",
    "create_metadata_file(csv_path, destination, remote=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9855de-f094-4db2-9131-88430115ad44",
   "metadata": {},
   "source": [
    "___\n",
    "### 3. **Creating the dst.csv file**\n",
    "In this section, we will create the dst file that contains the pressure, temperature and time data.  \n",
    "See below the steps that the extract_DST function does:  \n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7096f963-a919-4dd7-97d1-34eff6ebbf3f",
   "metadata": {},
   "source": [
    "- **Opening the CSV File**:\n",
    "  - Takes a file path to a CSV file containing time series data.\n",
    "  - Opens the CSV file using the `csv.reader` object.\n",
    "  \n",
    "- **Iterating Through CSV Rows**:\n",
    "  - Iterates through each row of the CSV file.\n",
    "  \n",
    "- **Extracting Tag ID**:\n",
    "  - Extracts the tag ID from the file path using the `extract_name` function (not provided).\n",
    "  \n",
    "- **Finding Target Line**:\n",
    "  - Searches for the line that contains the headers for the data of interest (\"Date/Time Stamp\", \"Pressure\", \"Temp\").\n",
    "  \n",
    "- **Reading Data**:\n",
    "  - Once the target line is found, starts reading data rows.\n",
    "  \n",
    "- **Formatting Date and Time**:\n",
    "  - Formats the date and time column using the `convert_to_utc_with_formatting` function.\n",
    "  - Converts the local time to UTC time based on the specified time zone.\n",
    "  \n",
    "- **Converting Data Types**:\n",
    "  - Converts the pressure and temperature data from strings to `numpy.float64` for numerical analysis.\n",
    "  \n",
    "- **Storing Data**:\n",
    "  - Stores the formatted data into a list for further processing.\n",
    "  \n",
    "- **Creating DataFrame**:\n",
    "  - After reading all data rows, converts the list of data into a Pandas DataFrame with columns ['time', 'pressure', 'temperature'].\n",
    "  \n",
    "- **Completeness Check**:\n",
    "  - Checks if the number of data points extracted matches the expected length.\n",
    "  - If they match, indicates completion; otherwise, suggests potential incompleteness.\n",
    "  \n",
    "- **Returning DataFrame**:\n",
    "  - Finally, returns the DataFrame containing the extracted data.\n",
    "\n",
    "This function primarily focuses on extracting time, pressure, and temperature data from a CSV file, converting the date and time to UTC time, and formatting the data for analysis. Check the function in the file data_conversion.py for further information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7c3c74-08a2-4457-a80b-491e31489121",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260fdf04-e86f-4e92-a8f0-21f03b4a0758",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_zone = \"Europe/Paris\"\n",
    "dst = extract_DST(csv_path, time_zone, remote=True)\n",
    "dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90417035-f1c9-4d72-80d3-384404c618be",
   "metadata": {},
   "outputs": [],
   "source": [
    "dst_save_path = destination + \"dst.csv\"\n",
    "dst.to_csv(dst_save_path, index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fdf61e0d-4a6e-40ae-8c38-6cd016fa5c60",
   "metadata": {},
   "source": [
    "___\n",
    "### 4. **Convert and format everything under the raw_test folder to the cleaned folder**\n",
    "This section has test purpose to see if it's easy and works correctly for the different tags in the **raw_test** folder.  \n",
    "Afterwards, the purpose is to do the same operation on the **raw** folder\n",
    "___\n",
    "#### Explenation of the code below :\n",
    "- **Folders and Time Zone Setup**:\n",
    "  - Defines folders (`raw_folder`, `destination_folder`) and time zone (`time_zone`).\n",
    "\n",
    "- **Destination Folder Creation**:\n",
    "  - Checks if the destination folder exists; if not, creates it.\n",
    "\n",
    "- **Processing Raw Data**:\n",
    "  - Iterates through raw files in the raw folder.\n",
    "  - Extracts tag ID and constructs destination paths.\n",
    "  - Creates tag-specific folders if they don't exist.\n",
    "  - Extracts tagging events and DST data from raw files.\n",
    "  - Saves extracted data to CSV files in respective tag folders.\n",
    "  - Creates metadata files for each raw file.\n",
    "\n",
    "- **Handling Incorrect Raw Folder**:\n",
    "  - Prints a message if the raw folder doesn't exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b345ec-d9f9-494c-a4c7-fc0fce417f87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "### Local\n",
    "if not remote:\n",
    "    raw_folder = \"../../all_raw/\"  # Folder name to explore\n",
    "    destination_folder = \"../../all_cleaned/\"\n",
    "    time_zone = \"Europe/Paris\"\n",
    "\n",
    "    if not os.path.exists(destination_folder):\n",
    "        os.mkdir(destination_folder)\n",
    "\n",
    "    # Check if the folder exists\n",
    "    if os.path.exists(raw_folder):\n",
    "        # Get list of files to iterate through\n",
    "        files = [\n",
    "            f\n",
    "            for f in os.listdir(raw_folder)\n",
    "            if os.path.isfile(os.path.join(raw_folder, f))\n",
    "        ]\n",
    "\n",
    "        # Wrap files list with tqdm for progress bar\n",
    "        for file_name in tqdm(files, desc=\"Processing files\"):\n",
    "            raw_file = os.path.join(raw_folder, file_name)\n",
    "\n",
    "            # Extract filename without extension\n",
    "            tag_id = extract_name(raw_file)\n",
    "            destination_path = os.path.join(destination_folder, tag_id)\n",
    "\n",
    "            # Check if the folder for the tag exists, if not, create it\n",
    "            if not os.path.exists(destination_path):\n",
    "                # print(\"Creating folder for tag:\", tag_id)\n",
    "                os.mkdir(destination_path)\n",
    "\n",
    "            ### Extracting tagging events from raw file\n",
    "            tag_events = extract_tagging_events(raw_file)\n",
    "            tagging_events_path = os.path.join(destination_path, \"tagging_events.csv\")\n",
    "            tag_events.to_csv(\n",
    "                tagging_events_path, index=False\n",
    "            )  ### Saving them at the right path\n",
    "\n",
    "            ### Extracting DST from raw file\n",
    "            tag_dst = extract_DST(raw_file, time_zone)\n",
    "            dst_path = os.path.join(destination_path, \"dst.csv\")\n",
    "            tag_dst.to_csv(dst_path, index=False)  ### Saving them at the right path\n",
    "\n",
    "            ###Creating metadata files\n",
    "            # print(\"creating_metadata\")\n",
    "            create_metadata_file(raw_file, destination_path)\n",
    "\n",
    "    # else:\n",
    "    # print(\"Wrong folder for raw files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e015ee-f9dc-4faf-a603-a3ae819c64d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19225a39-ed6e-49c9-a3a0-b35a78272fa5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "### Remote\n",
    "if remote:\n",
    "    s3 = s3fs.S3FileSystem(\n",
    "        anon=False,\n",
    "        client_kwargs={\n",
    "            \"endpoint_url\": \"https://s3.gra.perf.cloud.ovh.net\",  # S3 endpoint for OVH\n",
    "        },\n",
    "    )\n",
    "    raw_folder = \"s3://gfts-ifremer/tags/bargip/raw\"  # Folder name to explore\n",
    "    destination_folder = \"s3://gfts-ifremer/tags/bargip/clean_demo/\"\n",
    "    time_zone = \"Europe/Paris\"\n",
    "\n",
    "    # if not os.path.exists(destination_folder):\n",
    "    #     os.mkdir(destination_folder)\n",
    "\n",
    "    # Check if the folder exists\n",
    "    # if os.path.exists(raw_folder):\n",
    "\n",
    "    # Get list of files to iterate through\n",
    "    tag_ids = [\n",
    "        tag_id.replace(\"gfts-ifremer/tags/bargip/raw/\", \"\").replace(\".CSV\", \"\")\n",
    "        for tag_id in s3.ls(\"gfts-ifremer/tags/bargip/raw\")\n",
    "    ]\n",
    "\n",
    "    # Wrap files list with tqdm for progress bar\n",
    "    for tag_id in tqdm(tag_ids, desc=\"Processing files\"):\n",
    "        print(tag_id)\n",
    "        try:\n",
    "            file_path = f\"{raw_folder}/{tag_id}.CSV\"\n",
    "\n",
    "            # # Extract filename without extension\n",
    "            destination = f\"{destination_folder}{tag_id}\"\n",
    "\n",
    "            ### Extracting tagging events from raw file\n",
    "            tag_events = extract_tagging_events(file_path, remote=True)\n",
    "            te_save_path = f\"{destination}/tagging_events.csv\"\n",
    "            tag_events.to_csv(te_save_path, index=False)\n",
    "\n",
    "            # ### Extracting DST from raw file\n",
    "            tag_dst = extract_DST(file_path, time_zone, remote=True)\n",
    "            dst_save_path = f\"{destination}/dst.csv\"\n",
    "            tag_dst.to_csv(dst_save_path, index=False)\n",
    "\n",
    "            ###Creating metadata files\n",
    "            # print(\"creating_metadata\")\n",
    "            create_metadata_file(file_path, destination, remote=True)\n",
    "        except Exception as e:\n",
    "            print(f\"Error for {tag_id}\")\n",
    "            print(e)\n",
    "# else:\n",
    "# print(\"Wrong folder for raw files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184e7b1d-f994-4243-94e3-d7b396efc5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "toto = pd.read_csv(\"s3://gfts-ifremer/tags/bargip/cleaned/DK_A10625/dst.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b674e6-8a77-430a-9b02-da561140e4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"s3://gfts-ifremer/tags/bargip/raw/DK_A10625.CSV\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a1ce27-de2d-46ed-b980-23ccdea64cca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a92a4b0-a25a-45af-b929-cfdb142ab2f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run this cell if you computed the tags locally and you want to put all tags from local to the bucket\n",
    "\n",
    "import s3fs\n",
    "\n",
    "s3 = s3fs.S3FileSystem(\n",
    "    anon=False,\n",
    "    client_kwargs={\n",
    "        \"endpoint_url\": \"https://s3.gra.perf.cloud.ovh.net\",\n",
    "    },\n",
    ")\n",
    "\n",
    "if not remote:\n",
    "    s3.put(\"../../all_cleaned/\", \"gfts-ifremer/tags/bargip/cleaned\", recursive=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
